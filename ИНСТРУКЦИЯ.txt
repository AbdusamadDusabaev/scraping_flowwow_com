                                                 ================
                                                 || ИНСТРУКЦИЯ ||
                                                 ================

=========================================
НАСТРОЙКА ПАРСЕРА ПЕРЕД НАЧАЛОМ РАБОТЫ ||
========================================================================================================================
Перед запуском парсера необходимо сделать ряд простых действий:

1. Загрузить все необходимые библиотеки для работы парсера. Для этого необходимо в терминал ввести следующие команды:
- pip install selenium
- pip install pymysql
- pip install BeautifulSoup4
- pip install lxml

2. Ввести корректные данные в файле config.py. В этом файле определяются настройки базы данных, в которую будут
   загружены готовые данные. Переменные соответствуют следующим значениям:
- username - это имя пользователя для авторизации в базе данных.
- password - пароль пользователя для авторизации в базе данных.
- db_name - название базы данных, в которую идет запись.
- host - хост, на котором расположена база данных. Его можно посмотреть в настройках базы данных.
- post - порт, на котором расположена база данных. Его также можно посмотреть в настройках базы.
- table - название таблицы в базе данных, в которую идет запись.
- fields - строка, в которой необходимо через запятую прописать название полей, соответствующих полям "Название",
  "Полная цена", "Цена со скидкой", "Описание", "Состав", "Размер", "Ссылки на фотографии" в вашей базе данных.
========================================================================================================================


========================
ИСПОЛЬЗОВАНИЕ ПАРСЕРА ||
========================================================================================================================
После настройки парсера вы можете использовать его в автоматизированном формате. То есть вам не нужно будет самому
проходить капчи или вводить ссылки. Парсер все сделает за вас. Единственное, что вам нужно будет сделать - это выбрать
режим работы парсера при его запуске. Запускается парсер запуском файла (скрипта) main.py. У парсера есть два режима
работы: парсинг данных и запись данных в базу данных. После того как вы выберете парсинг данных, в файле result.csv
сохранятся данные, полученные из веб-ресурса. Эти данные можно вручную проверить и откорректировать для последующей
загрузки в базу данных. Режим записи данных в базу данных возьмет данные из того же файла result.csv и загрузит их в
базу данных (предполагается, что к моменту запуска данного режима, данные будут проверены и отредактированы).

!!! Не рекомендуется вносить какие-то правки в работу парсера, если вы не владеете языком программирования Python,
технологией Selenium, библиотеками BeautifulSoup, pymysql, json, time, csv, re и у вас нет знаний в веб-технологиях !!!

Шаблон работы с парсером выглядит следующим образом:
1. Используем режим парсинг для сбора информации из веб-ресурса
2. Корректируем данные в файле result.csv
3. Используем режим записи данных в базу данных
========================================================================================================================


==========================================================
ВОЗНИКЛИ ВОПРОСЫ ИЛИ ПРОБЛЕМЫ ПРИ ИСПОЛЬЗОВАНИИ ПАРСЕРА ||
========================================================================================================================
В случае если у вас возникнут какие-то вопросы или проблемы с парсером, вы всегда можете обратиться ко мне.

Мой Telegram: https://t.me/Buldog1702
Мой WhatsApp: +7(929)978-49-56
========================================================================================================================


               ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
               + ЖЕЛАЮ ВАМ ПРИЯТНОГО ИСПОЛЬЗОВАНИЯ И НАДЕЮСЬ НА ДАЛЬНЕЙШЕЕ СОТРУДНИЧЕСТВО!) +
               ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
